{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing tweets to NLP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronizing with Team Collaboration Folder in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3192,
     "status": "ok",
     "timestamp": 1675260446467,
     "user": {
      "displayName": "Aline Salviano",
      "userId": "17132370323163133714"
     },
     "user_tz": 180
    },
    "id": "VfRacX69zwVS",
    "outputId": "205ec222-8d4b-43bc-8d52-45cc87d9ea34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4476,
     "status": "ok",
     "timestamp": 1675260450936,
     "user": {
      "displayName": "Aline Salviano",
      "userId": "17132370323163133714"
     },
     "user_tz": 180
    },
    "id": "u7R6lh4bNBjG",
    "outputId": "1730714d-b2dc-4a4a-fdf4-b419586e3f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: emot in /usr/local/lib/python3.8/dist-packages (3.1)\n",
      "Requirement already satisfied: vader-multi in /usr/local/lib/python3.8/dist-packages (3.2.2.1)\n",
      "Requirement already satisfied: translatte in /usr/local/lib/python3.8/dist-packages (from vader-multi) (0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vader-multi) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vader-multi) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vader-multi) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vader-multi) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vader-multi) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install emot vader-multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaeG6Rq5u0r5"
   },
   "source": [
    "### Importing fundamental libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1675260450937,
     "user": {
      "displayName": "Aline Salviano",
      "userId": "17132370323163133714"
     },
     "user_tz": 180
    },
    "id": "j76yqGuwYLYy",
    "outputId": "e0f0328b-3e96-4959-a7f0-c393cbb7af7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "from emot import emo_unicode\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping lines with duplicate username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# August\n",
    "lula_tweets_august = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Capturas brutas/lula_tweets_agosto.csv')\n",
    "bolsonaro_tweets_august = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Capturas brutas/bolsonaro_tweets_agosto.csv')\n",
    "\n",
    "# September\n",
    "lula_tweets_september = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Capturas brutas/lula_tweets_setembro.csv')\n",
    "bolsonaro_tweets_september = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Capturas brutas/bolsonaro_tweets_setembro.csv')\n",
    "\n",
    "# October\n",
    "lula_tweets_october = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Capturas brutas/lula_tweets_outubro.csv')\n",
    "bolsonaro_tweets_october = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Capturas brutas/bolsonaro_tweets_outubro.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Transformer(dataframe):\n",
    "\n",
    "    \"\"\"Function that separates the date column to fit in %Y-%m-%d format and as datetime\"\"\"\n",
    "\n",
    "    new = dataframe['data'].str.split(\" \", n = 1, expand = True)\n",
    "\n",
    "    dataframe['date'] = new[0]\n",
    "    dataframe['excluir'] = new[1]\n",
    "\n",
    "    dataframe.drop(columns = ['data', 'excluir'], inplace = True)\n",
    "\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'], format = '%Y-%m-%d')\n",
    "\n",
    "    first_column = dataframe.pop('date')\n",
    "    dataframe.insert(0, 'date', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# August\n",
    "Data_Transformer(lula_tweets_august)\n",
    "Data_Transformer(bolsonaro_tweets_august)\n",
    "\n",
    "# September\n",
    "Data_Transformer(lula_tweets_september)\n",
    "Data_Transformer(bolsonaro_tweets_september)\n",
    "\n",
    "# October\n",
    "Data_Transformer(lula_tweets_october)\n",
    "Data_Transformer(bolsonaro_tweets_october)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# August\n",
    "lula_tweets_august.drop_duplicates(subset = ['username'], inplace = True)\n",
    "bolsonaro_tweets_august.drop_duplicates(subset = ['username'], inplace = True)\n",
    "\n",
    "# September\n",
    "lula_tweets_september.drop_duplicates(subset = ['username'], inplace = True)\n",
    "bolsonaro_tweets_september.drop_duplicates(subset = ['username'], inplace = True)\n",
    "\n",
    "# October\n",
    "lula_tweets_october.drop_duplicates(subset = ['username'], inplace = True)\n",
    "bolsonaro_tweets_october.drop_duplicates(subset = ['username'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# August\n",
    "lula_tweets_august.to_csv('lula_tweets_august.csv', encoding = 'utf-8', index = False)\n",
    "bolsonaro_tweets_august.to_csv('bolsonaro_tweets_august.csv', encoding = 'utf-8', index = False)\n",
    "\n",
    "# September\n",
    "lula_tweets_september.to_csv('lula_tweets_september.csv', encoding = 'utf-8', index = False)\n",
    "bolsonaro_tweets_september.to_csv('bolsonaro_tweets_september.csv', encoding = 'utf-8', index = False)\n",
    "\n",
    "# October\n",
    "lula_tweets_october.to_csv('lula_tweets_october.csv', encoding = 'utf-8', index = False)\n",
    "bolsonaro_tweets_october.to_csv('bolsonaro_tweets_october.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5ZcvhvdBZsS"
   },
   "source": [
    "\n",
    "### Datasets - automatic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Tx2rvZDSYTxV"
   },
   "outputs": [],
   "source": [
    "# Lula\n",
    "lula_august_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets sem duplicatas/lula_tweets_august.csv')\n",
    "lula_september_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets sem duplicatas/lula_tweets_september.csv')\n",
    "lula_october_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets sem duplicatas/lula_tweets_october.csv')\n",
    "\n",
    "# Bolsonaro\n",
    "bolsonaro_august_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets sem duplicatas/bolsonaro_tweets_august.csv')\n",
    "bolsonaro_september_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets sem duplicatas/bolsonaro_tweets_september.csv')\n",
    "bolsonaro_october_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets sem duplicatas/bolsonaro_tweets_october.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Epbw-RNeBEFe"
   },
   "outputs": [],
   "source": [
    "# Classificações automáticas (união august e september)\n",
    "\n",
    "# Lula\n",
    "lula_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets - classificação automática/lula_auto.csv')\n",
    "\n",
    "# Bolsonaro\n",
    "bolsonaro_auto = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets - classificação automática/bolsonaro_auto.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_uqbWOUMXhr"
   },
   "source": [
    "### Datasets - manual classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7UyY0EjMZnK"
   },
   "outputs": [],
   "source": [
    "# Lula\n",
    "lula_man = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets - classificação manual/classificacao_manual_lula.csv')\n",
    "\n",
    "# Bolsonaro\n",
    "bolsonaro_man = pd.read_csv('/content/drive/MyDrive/Projeto Tera: Eleição/Datasets - classificação manual/bolsonaro_man.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRfzw1SFBmLg"
   },
   "source": [
    "### Declaring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVS9E_tr_XiH"
   },
   "outputs": [],
   "source": [
    "# Remove emojis\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\" # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\" # Símbolos e pictogramas\n",
    "                           u\"\\U0001F680-\\U0001F6FF\" # Símbolos de transporte e mapa\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\" # Bandeiras (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "# Limpando os tweets\n",
    "def tweets_cleaner(tweet):\n",
    "    tweet = tweet.lower() # Converter para minúscula\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) # Remove espaços em branco adicionais\n",
    "    tweet= re.sub(r'@[A-Za-z0-9]+', '', tweet) # Remove menções\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # Substitui hashtags por palavras\n",
    "    tweet = re.sub(r'RT[\\s]+', '', tweet) # Remove RT\n",
    "    tweet = re.sub(r'https?:\\/\\/\\s+', '', tweet) # Remove hyperlink\n",
    "    tweet = re.sub(r'http', '', tweet) # Remove hyperlink\n",
    "    tweet = re.sub(r':+', '', tweet) # Remove : \n",
    "    tweet = re.sub(r'--+', '', tweet) # Remove :\n",
    "    tweet  = \"\".join([char for char in tweet if char not in string.punctuation]) # Remove pontuação\n",
    "    tweet = re.sub('[0-9]+', '', tweet) # Remove pontuação\n",
    "    tweet = tweet.strip('\\'\"') # Apara\n",
    "    return tweet\n",
    "\n",
    "# Substitui repetições\n",
    "def replace_duplicates(s):\n",
    "    padronizar = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return padronizar.sub(r\"\\1\\1\", s)\n",
    "\n",
    "\n",
    "# Tokeniza\n",
    "def tokenizador(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Remove stopwords\n",
    "stopword = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "\n",
    "# Stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "# Lemmatiza\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizador(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "\n",
    "# Sentiment\n",
    "def sentiment(compound):\n",
    "    if compound < 0:\n",
    "        return -1\n",
    "    elif compound == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "# Criar colunas\n",
    "def create_columns(df):\n",
    "    df['tweet_no_emoji'] = df['tweet'].apply(lambda x: remove_emoji(x))\n",
    "    df['cleaned_tweet'] = df['tweet_no_emoji'].apply(lambda x: tweets_cleaner(x))\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: replace_duplicates(x))\n",
    "    df['tweet_tokenize'] = df['cleaned_tweet'].apply(lambda x: tokenizador(x))\n",
    "    df['tweet_no_stopwords'] = df['tweet_tokenize'].apply(lambda x: remove_stopwords(x))\n",
    "    df['tweet_stemmize'] = df['tweet_no_stopwords'].apply(lambda x: stemming(x))\n",
    "    df['tweet_lemmatize'] = df['tweet_stemmize'].apply(lambda x: lemmatizador(x))\n",
    "    df['hashtag'] = df['tweet'].str.findall(r'#.*?(?=\\s|$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-b7RtyMfZFQZ"
   },
   "outputs": [],
   "source": [
    "lula_man.drop(labels=['Unnamed: 0', 'Unnamed: 0.1'],\n",
    "              axis=1,\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9VIzzmXYZ1N-"
   },
   "outputs": [],
   "source": [
    "lula_man = lula_man.rename({'Classificação Manual': 'sentiment_manual'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LAtjOJ7taQUd"
   },
   "outputs": [],
   "source": [
    "create_columns(lula_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cf7rinT2q8C0"
   },
   "outputs": [],
   "source": [
    "create_columns(bolsonaro_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9w6_o6WgaepP"
   },
   "outputs": [],
   "source": [
    "lula_man['hashtag']=lula_man['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "lula_man['hashtag']=lula_man['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "lula_man['hashtag']=lula_man['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "lula_man['hashtag']=lula_man['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "lula_man['tweet_sem_stopwords']=lula_man['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "lula_man['tweet_sem_stopwords']=lula_man['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "lula_man['tweet_sem_stopwords']=lula_man['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDWvM9y0rBJA"
   },
   "outputs": [],
   "source": [
    "bolsonaro_man['hashtag']=bolsonaro_man['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_man['hashtag']=bolsonaro_man['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_man['hashtag']=bolsonaro_man['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "bolsonaro_man['hashtag']=bolsonaro_man['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "bolsonaro_man['tweet_sem_stopwords']=bolsonaro_man['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_man['tweet_sem_stopwords']=bolsonaro_man['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_man['tweet_sem_stopwords']=bolsonaro_man['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-vc-UPv-IgFi"
   },
   "outputs": [],
   "source": [
    "# Criando colunas para Lula\n",
    "create_columns(lula_august_auto)\n",
    "create_columns(lula_september_auto)\n",
    "create_columns(lula_october_auto)\n",
    "\n",
    "# Criando colunas para Bolsonaro\n",
    "create_columns(bolsonaro_august_auto)\n",
    "create_columns(bolsonaro_september_auto)\n",
    "create_columns(bolsonaro_october_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8_2nyz8FODxD"
   },
   "outputs": [],
   "source": [
    "# Lulas's Sentiment\n",
    "lula_august_auto['sentiment'] = lula_august_auto['polarity'].apply(sentiment)\n",
    "lula_september_auto['sentiment'] = lula_september_auto['polarity'].apply(sentiment)\n",
    "lula_october_auto['sentiment'] = lula_october_auto['polarity'].apply(sentiment)\n",
    "\n",
    "# Bolsonaro's Sentiment\n",
    "bolsonaro_august_auto['sentiment'] = bolsonaro_august_auto['polarity'].apply(sentiment)\n",
    "bolsonaro_september_auto['sentiment'] = bolsonaro_september_auto['polarity'].apply(sentiment)\n",
    "bolsonaro_october_auto['sentiment'] = bolsonaro_october_auto['polarity'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYrQNQinBWJ_"
   },
   "source": [
    "## Improving automatic optimization with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stUu-Hr4DdgD"
   },
   "outputs": [],
   "source": [
    "results_vader_lula = pd.DataFrame(results_vader_lula)\n",
    "\n",
    "lula_auto['sentiment_vader'] = lula_auto['compound'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htOISk39BvKB"
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "results_vader_bolsonaro = []\n",
    "\n",
    "for tweet in bolsonaro_auto['tweet']:\n",
    "    analise = analyzer.polarity_scores(tweet)\n",
    "    resultados_vader_bolsonaro.append(analise)\n",
    "\n",
    "results_vader_bolsonaro = pd.DataFrame(results_vader_bolsonaro)\n",
    "\n",
    "bolsonaro_auto['sentiment_vader'] = bolsonaro_auto['compound'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdboSkQ0Ti7k"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tY1860KMSv5W"
   },
   "outputs": [],
   "source": [
    "lula_august_auto['hashtag']=lula_august_auto['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "lula_august_auto['hashtag']=lula_august_auto['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "lula_august_auto['hashtag']=lula_august_auto['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "lula_august_auto['hashtag']=lula_august_auto['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "lula_august_auto['tweet_sem_stopwords']=lula_august_auto['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "lula_august_auto['tweet_sem_stopwords']=lula_august_auto['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "lula_august_auto['tweet_sem_stopwords']=lula_august_auto['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JbTJpjLoSppV"
   },
   "outputs": [],
   "source": [
    "lula_september_auto['hashtag']=lula_september_auto['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "lula_september_auto['hashtag']=lula_september_auto['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "lula_september_auto['hashtag']=lula_september_auto['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "lula_september_auto['hashtag']=lula_september_auto['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "lula_september_auto['tweet_sem_stopwords']=lula_september_auto['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "lula_september_auto['tweet_sem_stopwords']=lula_september_auto['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "lula_september_auto['tweet_sem_stopwords']=lula_september_auto['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8n-CqduwTY13"
   },
   "outputs": [],
   "source": [
    "lula_october_auto['hashtag']=lula_october_auto['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "lula_october_auto['hashtag']=lula_october_auto['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "lula_october_auto['hashtag']=lula_october_auto['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "lula_october_auto['hashtag']=lula_october_auto['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "lula_october_auto['tweet_sem_stopwords']=lula_october_auto['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "lula_october_auto['tweet_sem_stopwords']=lula_october_auto['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "lula_october_auto['tweet_sem_stopwords']=lula_october_auto['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rVQc2P0lTzVx"
   },
   "outputs": [],
   "source": [
    "bolsonaro_august_auto['hashtag']=bolsonaro_august_auto['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_august_auto['hashtag']=bolsonaro_august_auto['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_august_auto['hashtag']=bolsonaro_august_auto['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "bolsonaro_august_auto['hashtag']=bolsonaro_august_auto['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "bolsonaro_august_auto['tweet_sem_stopwords']=bolsonaro_august_auto['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_august_auto['tweet_sem_stopwords']=bolsonaro_august_auto['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_august_auto['tweet_sem_stopwords']=bolsonaro_august_auto['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "b8g0M2E9TzNX"
   },
   "outputs": [],
   "source": [
    "bolsonaro_september_auto['hashtag']=bolsonaro_september_auto['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_september_auto['hashtag']=bolsonaro_september_auto['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_september_auto['hashtag']=bolsonaro_september_auto['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "bolsonaro_september_auto['hashtag']=bolsonaro_september_auto['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "bolsonaro_september_auto['tweet_sem_stopwords']=bolsonaro_september_auto['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_september_auto['tweet_sem_stopwords']=bolsonaro_september_auto['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_september_auto['tweet_sem_stopwords']=bolsonaro_september_auto['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lmrBqQaZTzId"
   },
   "outputs": [],
   "source": [
    "bolsonaro_october_auto['hashtag']=bolsonaro_october_auto['hashtag'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_october_auto['hashtag']=bolsonaro_october_auto['hashtag'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_october_auto['hashtag']=bolsonaro_october_auto['hashtag'].replace('\\'','',regex=True).astype(str)\n",
    "bolsonaro_october_auto['hashtag']=bolsonaro_october_auto['hashtag'].replace('\\#','',regex=True).astype(str)\n",
    "bolsonaro_october_auto['tweet_sem_stopwords']=bolsonaro_october_auto['tweet_sem_stopwords'].replace('\\[','',regex=True).astype(str)\n",
    "bolsonaro_october_auto['tweet_sem_stopwords']=bolsonaro_october_auto['tweet_sem_stopwords'].replace('\\]','',regex=True).astype(str)\n",
    "bolsonaro_october_auto['tweet_sem_stopwords']=bolsonaro_october_auto['tweet_sem_stopwords'].replace('\\'','',regex=True).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJaGwqzPUI9p"
   },
   "source": [
    "### Transforming into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YU3Dp_KBUSCc"
   },
   "outputs": [],
   "source": [
    "# august\n",
    "lula_august_auto.to_csv('lula_august_auto.csv', encoding = 'utf-8', index = False)\n",
    "bolsonaro_august_auto.to_csv('bolsonaro_august_auto.csv', encoding = 'utf-8', index = False)\n",
    "\n",
    "# september\n",
    "lula_september_auto.to_csv('lula_september_auto.csv', encoding = 'utf-8', index = False)\n",
    "bolsonaro_september_auto.to_csv('bolsonaro_september_auto.csv', encoding = 'utf-8', index = False)\n",
    "\n",
    "# october\n",
    "lula_october_auto.to_csv('lula_october_auto.csv', encoding = 'utf-8', index = False)\n",
    "bolsonaro_october_auto.to_csv('bolsonaro_october_auto.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Emqs9NOWatg2"
   },
   "outputs": [],
   "source": [
    "lula_man.to_csv('lula_man.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJ9opaC2rIg5"
   },
   "outputs": [],
   "source": [
    "bolsonaro_man.to_csv('bolsonaro_man.csv', encoding = 'utf-8', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
